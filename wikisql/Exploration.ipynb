{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise arguments etc. Should output the folder containing the pretrained model, may be necessary to change data_path to an absolute path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data_model/wikisql/'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import opts\n",
    "import argparse\n",
    "import os\n",
    "data_path = '../data_model/wikisql/'\n",
    "model_path = os.path.join(data_path,'pretrain.pt')\n",
    "parser = argparse.ArgumentParser(description='Exploration.ipynb')\n",
    "opts.translate_opts(parser)\n",
    "opt = parser.parse_args(\n",
    "    [\"-split\",\"pred\",\"-output\",\"pred.txt\",\"-data_path\",data_path,\"-model_path\",model_path])\n",
    "\n",
    "opt.anno = os.path.join(\n",
    "    opt.data_path, 'annotated_ent/{}.jsonl'.format(opt.split))\n",
    "opt.source_file = os.path.join(\n",
    "    opt.data_path, 'data/{}.jsonl'.format(opt.split))\n",
    "opt.db_file = os.path.join(opt.data_path, 'data/{}.db'.format(opt.split))\n",
    "opt.pre_word_vecs = os.path.join(opt.data_path, 'embedding')\n",
    "opt.data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data_model/wikisql/pretrain.pt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import table\n",
    "import glob\n",
    "import json\n",
    "torch.cuda.set_device(opt.gpu)\n",
    "dummy_parser = argparse.ArgumentParser(description='train.py')\n",
    "opts.model_opts(dummy_parser)\n",
    "opts.train_opts(dummy_parser)\n",
    "dummy_opt = dummy_parser.parse_known_args([])[0]\n",
    "fn_model = glob.glob(opt.model_path)[0]\n",
    "opt.model=fn_model\n",
    "fn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained model - may take time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(opt.model,\n",
    "                                map_location=lambda storage, loc: storage)\n",
    "fields = table.IO.TableDataset.load_fields(checkpoint['vocab'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the translation model running. If the embedding folder is not set correctly this may attempt to download the GloVe vectors directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    }
   ],
   "source": [
    "translator = table.Translator(opt, dummy_opt.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a new table. This example is from the training data, but can be modified. The rows are not used for the query, but at least one should exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables={}\n",
    "table_instance={\"header\": \n",
    "       [\"Season\", \"Driver\", \"Team\", \"Engine\", \"Poles\", \"Wins\", \"Podiums\", \"Points\", \"Margin of defeat\"],\n",
    "       \"page_title\": \"List of Formula One World Drivers' Championship runners-up\", \n",
    "       \"types\": [\"real\", \"text\", \"text\", \"text\", \"real\", \"real\", \"real\", \"text\", \"text\"], \n",
    "       \"id\": \"1-10753917-1\",\n",
    "       \"section_title\": \"By season\", \n",
    "       \"caption\": \"By season\",\n",
    "       \"rows\": [[1950, \"Juan Manuel Fangio\", \"Alfa Romeo\", \"Alfa Romeo\", 4, 3, 3, \"27\", \"3\"], \n",
    "                #skip rows\n",
    "                [2011, \"Jenson Button\", \"McLaren\", \"Mercedes\", 0, 3, 12, \"270\", \"122\"]], \n",
    "       \"name\": \"table_10753917_1\"\n",
    "      }\n",
    "tables[table_instance['id']]=table_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a question. The SQL field describes the expected query when training or testing. In this notebook it is not used, but it should still make sense for the table (e.g. conds should not specify a column number which is not in the table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = {\"phase\": 1, \n",
    "            \"table_id\": \"1-10753917-1\", \n",
    "            \"question\": \"How many wins did the ferrari team have after 1950 and before 1960?\", \n",
    "            \"sql\": {\"sel\": 1, \"conds\": [[2, 0, \"Williams\"], [8, 0, \"2\"]], \"agg\": 3}\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This connects to a Stanford CoreNLP server to annotate the question. The server should be running \n",
    "on http://localhost:9000/ by default, this can be modified in annotate.py when instantiating CoreNLPClient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotate import annotate_example\n",
    "annotated_question = annotate_example(question, table_instance)\n",
    "#annotated_question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add POS annotations to question. Requires spaCy model installed as described in https://spacy.io/models/en#en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import codecs\n",
    "import json\n",
    "from spacy.tokens import Doc\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "w_list = annotated_question['question']['gloss']\n",
    "ws_list = [it.isspace() for it in annotated_question['question']['after']]\n",
    "doc = Doc(nlp.vocab, words=w_list, spaces=ws_list)\n",
    "for name, proc in nlp.pipeline:\n",
    "    doc = proc(doc)\n",
    "annotated_question['question']['ent'] = [tk.tag_ for tk in doc]\n",
    "assert(len(annotated_question['question']['ent']) == len(annotated_question['question']['words']))\n",
    "#annotated_question['question']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually generate the SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SELECT SUM col5 FROM table WHERE col2 = ferrari AND col0 > 1950 AND col0 < 1960"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_list = [annotated_question]\n",
    "data = table.IO.TableDataset(js_list, translator.fields, None, False)\n",
    "test_data = table.IO.OrderedIterator(dataset=data,device=opt.gpu, batch_size=opt.batch_size, train=False, sort=True, sort_within_batch=False)\n",
    "batch=next(iter(test_data))\n",
    "result_list=translator.translate(batch)\n",
    "pred = result_list[0]\n",
    "pred.predict(annotated_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
